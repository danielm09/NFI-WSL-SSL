{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from utils.data_loading import SSL_Dataset\n",
    "from training.train_model import trainMAE\n",
    "from models.fcmae import FCMAE\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Self-Supervised Masked Autoencoder (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load means and stds for data standardization\n",
    "means_np = np.load('../data/sen2_65k_181b_means.npy')\n",
    "stds_np = np.load('../data/sen2_65k_181b_stds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_train_set_path = \"../data/crops_train_all_SSL.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transforms to be applied to training data\n",
    "train_transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_train_set = SSL_Dataset(ssl_train_set_path,\n",
    "                            transform=train_transforms,\n",
    "                            standardize=True,\n",
    "                            means_np=means_np,\n",
    "                            stds_np=stds_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters and load model (FCMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "lr = 0.0015\n",
    "\n",
    "depths = [2, 2, 6, 2]\n",
    "dims = [40, 80, 160, 320]\n",
    "\n",
    "img_size = 56 #NxN pixels\n",
    "patch_size = 8 #NxN pixels\n",
    "in_chans = 181 #bands\n",
    "mask_ratio = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCMAE(img_size=img_size, img_size=img_size, in_chans=in_chans, mask_ratio=mask_ratio, depths=depths, dims=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a lr scheduler to run 700 epochs at lr=0.0015 than change lr to 0.00015\n",
    "def lr_lambda(epoch):\n",
    "    return lr if epoch < 700 else 0.00015\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_train_loader = DataLoader(ssl_train_set, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define whether to log model training to wandb\n",
    "log_to_wandb = False\n",
    "wandb_proj = 'ifn-ssl-mae'\n",
    "if log_to_wandb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define run configs\n",
    "save_model = False\n",
    "run_config = {\n",
    "    \"epochs\":num_epochs,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"learning_rate\":lr,\n",
    "    \"optimizer\":\"Adam\",\n",
    "    \"criterion\":\"MSE\", #Mean Squared Error (computed internally by the model)\n",
    "    \"augmentations\":\"H&V_Flip\",\n",
    "    \"architecture\":\"FCMAE\",\n",
    "    \"depths\":depths,\n",
    "    \"dims\":dims\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMAE(model,\n",
    "         ssl_train_loader,\n",
    "         optimizer,\n",
    "         mask_ratio,\n",
    "         scheduler,\n",
    "         log_to_wandb=log_to_wandb,\n",
    "         wandb_proj=wandb_proj,\n",
    "         run_config=run_config,\n",
    "         save=save_model\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
