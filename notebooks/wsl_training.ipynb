{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/test_torch_pub/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from training.train_model import trainWSLModel\n",
    "from models.convnextv2_unet import ConvNeXtV2_unet\n",
    "from utils.data_loading import WSL_Dataset\n",
    "from utils.helper import remap_checkpoint_keys\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load WSL train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load means and stds for data standardization\n",
    "means_np = np.load('../data/sen2_65k_181b_means.npy')\n",
    "stds_np = np.load('../data/sen2_65k_181b_stds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and test set paths\n",
    "wsl_train_set_path = \"../data/crops_train_seg_all_64x64_181b_augmented.hdf5\"\n",
    "wsl_test_set_path = \"../data/crops_test_seg_all_64x64_181b.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transforms to be applied to training data\n",
    "train_transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl_train_set = WSL_Dataset(wsl_train_set_path,\n",
    "                        transform=train_transforms,\n",
    "                        standardize=True,\n",
    "                        means_np=means_np,\n",
    "                        stds_np=stds_np,\n",
    "                        downsample_classes=[5,10,14,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl_test_set = WSL_Dataset(wsl_test_set_path,\n",
    "                        transform=train_transforms,\n",
    "                        standardize=True,\n",
    "                        means_np=means_np,\n",
    "                        stds_np=stds_np,\n",
    "                        downsample_classes=[5,10,14,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Weakly Supervised Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters and create model (ConvNext-V2 U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "\n",
    "depths = [2, 2, 6, 2]\n",
    "dims = [40, 80, 160, 320]\n",
    "\n",
    "img_size = 64 #NxN pixels\n",
    "patch_size = 8 #NxN pixels\n",
    "in_chans = 181 #bands\n",
    "\n",
    "num_classes = 21 #20 classes + 1 additional class for unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeXtV2_unet(img_size=img_size, patch_size=patch_size, in_chans=in_chans, num_classes=num_classes, depths=depths, dims=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss criterion\n",
    "#set weight of the last class (20 - unlabeled pixels) to zero\n",
    "ws = [1 for i in range(21)]\n",
    "ws[-1] = 0\n",
    "ws = torch.tensor(ws).float().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=ws)\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl_train_loader = DataLoader(wsl_train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "wsl_test_loader = DataLoader(wsl_test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define whether to log model statistics to wandb\n",
    "log_to_wandb = False\n",
    "wandb_proj = 'ifn-wsl'\n",
    "if log_to_wandb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define run configs\n",
    "test_eval = True #compute statistics for the test set\n",
    "mask_pixel = 20 #mask pixels equal to 20 (unlabeled)\n",
    "save_model = False\n",
    "run_config = {\n",
    "    \"epochs\":num_epochs,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"learning_rate\":lr,\n",
    "    \"optimizer\":\"Adam\",\n",
    "    \"criterion\":\"WCE\", #weighted Cross-Entropy\n",
    "    \"augmentations\":\"H&V_Flip\",\n",
    "    \"architecture\":\"ConvNextV2_UNet\",\n",
    "    \"depths\":depths,\n",
    "    \"dims\":dims\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWSLModel(model,\n",
    "            wsl_train_loader,\n",
    "            wsl_test_loader,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            test_eval=test_eval,\n",
    "            mask_pixel=mask_pixel,\n",
    "            log_to_wandb=log_to_wandb,\n",
    "            wandb_proj=wandb_proj,\n",
    "            run_config=run_config,\n",
    "            save=save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Self-Supervised pretrained MAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "\n",
    "depths = [2, 2, 6, 2]\n",
    "dims = [40, 80, 160, 320]\n",
    "\n",
    "img_size = 64 #NxN pixels\n",
    "patch_size = 8 #NxN pixels\n",
    "in_chans = 181 #bands\n",
    "\n",
    "num_classes = 21 #20 classes + 1 additional class for unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MAE model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Refer to README.md on models/saved_models to download our pretrained model.*\n",
    "\n",
    "*Alternatively, load your own saved model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_weights = torch.load(\"../models/saved_models/MAEModel_FCMAE_depths[2-2-6-2]_dim[40-80-160-320]_batch128_lr00015_AugH&V_Flip_Adam_MSE.pt\")\n",
    "\n",
    "#harmonize dict keys to facilitate weight transfer\n",
    "pretrained_model_weights = remap_checkpoint_keys(pretrained_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ConvNext-V2 U-Net model and transfer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'upsample_layers.0.conv.weight', 'upsample_layers.0.conv.bias', 'upsample_layers.0.norm.weight', 'upsample_layers.0.norm.bias', 'upsample_layers.1.conv.weight', 'upsample_layers.1.conv.bias', 'upsample_layers.1.norm.weight', 'upsample_layers.1.norm.bias', 'upsample_layers.2.conv.weight', 'upsample_layers.2.conv.bias', 'upsample_layers.2.norm.weight', 'upsample_layers.2.norm.bias', 'upsample_layers.3.conv.weight', 'upsample_layers.3.conv.bias', 'upsample_layers.3.norm.weight', 'upsample_layers.3.norm.bias', 'initial_conv_upsample.0.weight', 'initial_conv_upsample.0.bias', 'initial_conv_upsample.1.weight', 'initial_conv_upsample.1.bias'], unexpected_keys=['mask_token'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new model\n",
    "model = ConvNeXtV2_unet(img_size=img_size, patch_size=patch_size, in_chans=in_chans, num_classes=num_classes, depths=depths, dims=dims)\n",
    "\n",
    "#transfer weights from pretrained model\n",
    "model.load_state_dict(pretrained_model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss criterion\n",
    "#set weight of the last class (20 - unlabeled pixels) to zero\n",
    "ws = [1 for i in range(21)]\n",
    "ws[-1] = 0\n",
    "ws = torch.tensor(ws).float().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=ws)\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl_train_loader = DataLoader(wsl_train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "wsl_test_loader = DataLoader(wsl_test_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define whether to log model statistics to wandb\n",
    "log_to_wandb = False\n",
    "wandb_proj = 'ifn-wsl'\n",
    "if log_to_wandb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define run configs\n",
    "test_eval = True #compute statistics for the test set\n",
    "mask_pixel = 20 #mask pixels equal to 20 (unlabeled)\n",
    "save_model = False\n",
    "run_config = {\n",
    "    \"epochs\":num_epochs,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"learning_rate\":lr,\n",
    "    \"optimizer\":\"Adam\",\n",
    "    \"criterion\":\"WCE\", #weighted Cross-Entropy\n",
    "    \"augmentations\":\"H&V_Flip\",\n",
    "    \"architecture\":\"ConvNextV2_UNet\",\n",
    "    \"depths\":depths,\n",
    "    \"dims\":dims\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWSLModel(model,\n",
    "            wsl_train_loader,\n",
    "            wsl_test_loader,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            test_eval=test_eval,\n",
    "            mask_pixel=mask_pixel,\n",
    "            log_to_wandb=log_to_wandb,\n",
    "            wandb_proj=wandb_proj,\n",
    "            run_config=run_config,\n",
    "            save=save_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_torch_pub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
